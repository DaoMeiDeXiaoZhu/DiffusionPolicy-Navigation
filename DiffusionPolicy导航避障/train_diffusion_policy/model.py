import torch
import torch.nn as nn
import torch.nn.functional as F

class DiffusionTransformer(nn.Module):
    def __init__(self, state_dim=360, action_dim=2, embed_dim=64, hidden=128, n_layers=3):
        super().__init__()

        # ============================================================
        # 1. 图像缩放层（降低分辨率以减少显存）
        #    原始图像 480×640 → 缩放到 120×160
        #    这样 CNN 输出维度大幅减少，显存降低 10 倍以上
        # ============================================================
        self.resize = nn.Upsample(size=(120, 160), mode="bilinear")

        # ============================================================
        # 2. CNN 图像编码器
        #    输入: (B*T, 3, 120, 160)
        #    输出: (B*T, 64, 15, 20)
        #    作用: 提取视觉特征
        # ============================================================
        self.cnn = nn.Sequential(
            nn.Conv2d(3, 16, 4, 2, 1),  # 输出: 16×60×80
            nn.ReLU(),
            nn.Conv2d(16, 32, 4, 2, 1), # 输出: 32×30×40
            nn.ReLU(),
            nn.Conv2d(32, 64, 4, 2, 1), # 输出: 64×15×20
            nn.ReLU(),
        )

        # ============================================================
        # 3. 自动计算 CNN flatten 后的维度
        #    这样模型不依赖固定图像大小，更健壮
        # ============================================================
        with torch.no_grad():
            dummy = torch.zeros(1, 3, 120, 160)
            out = self.cnn(dummy)
            self.cnn_out_dim = out.numel()  # 64*15*20 = 19200

        # ============================================================
        # 4. 将 CNN 输出映射到 Transformer 的 embed_dim（两层 MLP）
        # ============================================================
        self.img_fc = nn.Sequential(
            nn.Linear(self.cnn_out_dim, embed_dim * 2),
            nn.ReLU(),
            nn.Linear(embed_dim * 2, embed_dim)
        )

        # ============================================================
        # 5. 雷达状态编码器（两层 MLP）
        # ============================================================
        self.state_fc = nn.Sequential(
            nn.Linear(state_dim, embed_dim * 2),
            nn.ReLU(),
            nn.Linear(embed_dim * 2, embed_dim)
        )

        # ============================================================
        # 6. 动作编码器（两层 MLP）
        # ============================================================
        self.action_fc = nn.Sequential(
            nn.Linear(action_dim, embed_dim * 2),
            nn.ReLU(),
            nn.Linear(embed_dim * 2, embed_dim)
        )

        # ============================================================
        # 7. 时间步编码（Diffusion timestep embedding）
        #    输入: t ∈ [0, 999]
        #    输出: (B, embed_dim)
        # ============================================================
        self.t_embed = nn.Embedding(1000, embed_dim)

        # ============================================================
        # 8. Transformer 编码器
        #    输入: (B, T, embed_dim)
        #    输出: (B, T, embed_dim)
        #    作用: 融合时序信息（动作序列）
        # ============================================================
        layer = nn.TransformerEncoderLayer(
            d_model=embed_dim,
            nhead=4,
            dim_feedforward=hidden,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(layer, num_layers=n_layers)

        # ============================================================
        # 9. 输出层：预测噪声 εθ
        #    输出: (B, T, action_dim)
        # ============================================================
        self.out = nn.Linear(embed_dim, action_dim)

    def forward(self, img, state, noisy_action, t):
        # img shape: (B, T, C, H, W)
        B, T, C, H, W = img.shape

        # ============================================================
        # 1. 图像 reshape + 缩放
        #    (B, T, C, H, W) → (B*T, C, H, W)
        #    再 resize → (B*T, C, 120, 160)
        # ============================================================
        img = img.reshape(B*T, C, H, W)
        img = self.resize(img)

        # ============================================================
        # 2. CNN 提取视觉特征
        #    输出: (B*T, 64, 15, 20)
        # ============================================================
        feat = self.cnn(img)

        # ============================================================
        # 3. flatten + 映射到 embed_dim
        #    (B*T, 64*15*20) → (B*T, embed_dim)
        #    再 reshape → (B, T, embed_dim)
        # ============================================================
        feat = feat.reshape(B*T, -1)
        img_emb = self.img_fc(feat).reshape(B, T, -1)

        # ============================================================
        # 4. 状态编码 (B, T, 360) → (B, T, embed_dim)
        # ============================================================
        state_emb = self.state_fc(state)

        # ============================================================
        # 5. 动作编码 (B, T, 2) → (B, T, embed_dim)
        # ============================================================
        act_emb = self.action_fc(noisy_action)

        # ============================================================
        # 6. 时间步编码 (B,) → (B, 1, embed_dim) → repeat → (B, T, embed_dim)
        # ============================================================
        t_emb = self.t_embed(t).unsqueeze(1).repeat(1, T, 1)

        # ============================================================
        # 7. 融合所有模态：图像 + 雷达 + 动作 + 时间步
        #    得到最终 Transformer 输入
        # ============================================================
        x = img_emb + state_emb + act_emb + t_emb

        # ============================================================
        # 8. Transformer 编码时序信息
        # ============================================================
        x = self.transformer(x)

        # ============================================================
        # 9. 输出噪声预测 εθ
        # ============================================================
        return self.out(x)
